{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08220b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import os\n",
    "import glob\n",
    "import concurrent.futures\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf5c0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    file_extension = os.path.splitext(file_path)[1][1:].lower()  # חותכים את ה- \".\" מהסיומת\n",
    "    read_func = getattr(pd, f\"read_{file_extension}\")\n",
    "    return read_func(file_path)\n",
    "    \n",
    "def save_file(df, file_path):\n",
    "    file_extension = os.path.splitext(file_path)[1][1:].lower()  # חותכים את ה- \".\" מהסיומת\n",
    "    save_func = getattr(df, f\"to_{file_extension}\")\n",
    "    save_func(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92403773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_file('./time_series.csv')\n",
    "df.replace(\"not_a_number\", pd.NA, inplace=True)\n",
    "df = df.dropna()\n",
    "df = df.dropna(subset=[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e54ff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data_day_01.csv\n",
      "Saved data_day_02.csv\n",
      "Saved data_day_03.csv\n",
      "Saved data_day_04.csv\n",
      "Saved data_day_05.csv\n",
      "Saved data_day_06.csv\n",
      "Saved data_day_07.csv\n",
      "Saved data_day_08.csv\n",
      "Saved data_day_09.csv\n",
      "Saved data_day_10.csv\n",
      "Saved data_day_11.csv\n",
      "Saved data_day_12.csv\n",
      "Saved data_day_13.csv\n",
      "Saved data_day_14.csv\n",
      "Saved data_day_15.csv\n",
      "Saved data_day_16.csv\n",
      "Saved data_day_17.csv\n",
      "Saved data_day_18.csv\n",
      "Saved data_day_19.csv\n",
      "Saved data_day_20.csv\n",
      "Saved data_day_21.csv\n",
      "Saved data_day_22.csv\n",
      "Saved data_day_23.csv\n",
      "Saved data_day_24.csv\n",
      "Saved data_day_25.csv\n",
      "Saved data_day_26.csv\n",
      "Saved data_day_27.csv\n",
      "Saved data_day_28.csv\n",
      "Saved data_day_29.csv\n",
      "Saved data_day_30.csv\n"
     ]
    }
   ],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "for day, group in df.groupby(df[\"timestamp\"].dt.day):\n",
    "    filename = f\"data_day_{day:02d}.csv\" \n",
    "    group.to_csv(filename, index=False)\n",
    "    print(f\"Saved {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee07d492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28  1 10 23  5 26  6  7 19 13  4 14 20 16 24 15  3 27  8 12 25 29 30 22\n",
      " 18 21  2 11 17  9]\n",
      "b\"\\x80\\x04\\x95'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x08__main__\\x94\\x8c\\x16process_hourly_average\\x94\\x93\\x94.\"\n",
      "Processed hourly averages for data_day_14.csv -> hourly_avg_day_14.csv\n",
      "Processed hourly averages for data_day_20.csv -> hourly_avg_day_20.csv\n",
      "Processed hourly averages for data_day_07.csv -> hourly_avg_day_07.csv\n",
      "Processed hourly averages for data_day_13.csv -> hourly_avg_day_13.csv\n",
      "Processed hourly averages for data_day_10.csv -> hourly_avg_day_10.csv\n",
      "Processed hourly averages for data_day_19.csv -> hourly_avg_day_19.csv\n",
      "Processed hourly averages for data_day_16.csv -> hourly_avg_day_16.csv\n",
      "Processed hourly averages for data_day_05.csv -> hourly_avg_day_05.csv\n",
      "Processed hourly averages for data_day_06.csv -> hourly_avg_day_06.csv\n",
      "Processed hourly averages for data_day_26.csv -> hourly_avg_day_26.csv\n",
      "Processed hourly averages for data_day_23.csv -> hourly_avg_day_23.csv\n",
      "Processed hourly averages for data_day_24.csv -> hourly_avg_day_24.csv\n",
      "Processed hourly averages for data_day_15.csv -> hourly_avg_day_15.csv\n",
      "Processed hourly averages for data_day_28.csv -> hourly_avg_day_28.csv\n",
      "Processed hourly averages for data_day_01.csv -> hourly_avg_day_01.csv\n",
      "Processed hourly averages for data_day_04.csv -> hourly_avg_day_04.csv\n",
      "Processed hourly averages for data_day_27.csv -> hourly_avg_day_27.csvProcessed hourly averages for data_day_08.csv -> hourly_avg_day_08.csv\n",
      "\n",
      "Processed hourly averages for data_day_03.csv -> hourly_avg_day_03.csv\n",
      "Processed hourly averages for data_day_21.csv -> hourly_avg_day_21.csv\n",
      "Processed hourly averages for data_day_25.csv -> hourly_avg_day_25.csv\n",
      "Processed hourly averages for data_day_12.csv -> hourly_avg_day_12.csv\n",
      "Processed hourly averages for data_day_29.csv -> hourly_avg_day_29.csv\n",
      "Processed hourly averages for data_day_17.csv -> hourly_avg_day_17.csv\n",
      "Processed hourly averages for data_day_18.csv -> hourly_avg_day_18.csv\n",
      "Processed hourly averages for data_day_11.csv -> hourly_avg_day_11.csv\n",
      "Processed hourly averages for data_day_09.csv -> hourly_avg_day_09.csv\n",
      "Processed hourly averages for data_day_02.csv -> hourly_avg_day_02.csv\n",
      "Processed hourly averages for data_day_30.csv -> hourly_avg_day_30.csv\n",
      "Processed hourly averages for data_day_22.csv -> hourly_avg_day_22.csv\n",
      "Merged all hourly averages into final_hourly_averages.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_hourly_average(day):\n",
    "    try:\n",
    "        filename = f\"data_day_{day:02d}.csv\"\n",
    "        df_day = read_file(filename)\n",
    "\n",
    "        df_day[\"timestamp\"] = pd.to_datetime(df_day[\"timestamp\"],errors='coerce')\n",
    "\n",
    "        df_day[\"hour\"] = df_day[\"timestamp\"].dt.strftime(\"%Y-%m-%d %H:00\")  # פורמט YYYY-MM-DD HH:00\n",
    "\n",
    "        hourly_avg = df_day.groupby(\"hour\")[\"value\"].mean().reset_index()\n",
    "\n",
    "        all_hours = pd.date_range(start=f\"2025-06-{day:02d} 00:00\", periods=24, freq=\"H\").strftime(\"%Y-%m-%d %H:00\")\n",
    "        all_hours_df = pd.DataFrame(all_hours, columns=[\"hour\"])\n",
    "\n",
    "        hourly_avg = pd.merge(all_hours_df, hourly_avg, on=\"hour\", how=\"left\")\n",
    "        hourly_avg[\"value\"].fillna(0, inplace=True)  \n",
    "\n",
    "        avg_filename = f\"hourly_avg_day_{day:02d}.csv\"\n",
    "        hourly_avg.to_csv(avg_filename, index=False)\n",
    "        print(f\"Processed hourly averages for {filename} -> {avg_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {day}: {e}\")\n",
    "\n",
    "       \n",
    "# df = pd.read_csv(\"data.csv\") \n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "unique_days = df[\"timestamp\"].dt.day.unique()\n",
    "print(unique_days)\n",
    "print(pickle.dumps(process_hourly_average))  \n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    executor.map(process_hourly_average, unique_days, chunksize=1)\n",
    "\n",
    "def load_csv(filename):\n",
    "    return read_file(filename)\n",
    "\n",
    "hourly_avg_files = [f\"hourly_avg_day_{day:02d}.csv\" for day in unique_days]\n",
    "df_combined = pd.concat(map(load_csv, hourly_avg_files), ignore_index=True)\n",
    "\n",
    "df_combined[\"hour\"] = pd.to_datetime(df_combined[\"hour\"], errors=\"coerce\")\n",
    "df_combined[\"hour_only\"] = df_combined[\"hour\"].dt.hour\n",
    "\n",
    "df_grouped = df_combined.groupby(\"hour_only\").agg({\n",
    "    \"hour\":\"min\",\n",
    "    \"value\": \"mean\" \n",
    "}).reset_index()\n",
    "\n",
    "df_combined[\"hour\"] = df_combined[\"hour\"].dt.strftime(\"%Y-%m-%d %H:00\")  \n",
    "df_grouped = df_grouped.drop(columns=[\"hour_only\"])\n",
    "\n",
    "save_file(df_grouped, \"final_hourly_averages.csv\")\n",
    "print(\"Merged all hourly averages into final_hourly_averages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0e91a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
